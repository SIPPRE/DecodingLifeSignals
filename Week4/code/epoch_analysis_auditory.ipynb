{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNE Sample Dataset: Auditory and Visual Evoked Responses\n",
    "\n",
    "This notebook uses the MNE-Python sample dataset, which contains MEG and EEG recordings from a single subject who was presented with auditory and visual stimuli.\n",
    "\n",
    "## Dataset Details:\n",
    "- **Subject**: A healthy adult volunteer\n",
    "- **Recording**: 204 planar gradiometers, 102 magnetometers, and 60 EEG channels\n",
    "- **Paradigm**: Simple auditory and visual stimulation with left/right conditions\n",
    "- **Trials**: Approximately 100 epochs each for the different conditions\n",
    "\n",
    "## Experimental Conditions in Detail:\n",
    "\n",
    "### Auditory Experiment\n",
    "The auditory experiment presents tone beeps to either the left or right ear:\n",
    "- **Stimulus type**: Pure tone beeps\n",
    "- **Frequency**: 1 kHz (1000 Hz)\n",
    "- **Duration**: 50 ms\n",
    "- **Intensity**: 60 dB sound pressure level\n",
    "- **Presentation**: \n",
    "  - Left ear (Event code: '1' or 'Auditory/Left')\n",
    "  - Right ear (Event code: '2' or 'Auditory/Right')\n",
    "- **Inter-stimulus interval**: Variable, around 1-1.5 seconds\n",
    "- **Neural response**: \n",
    "  - Both conditions activate the auditory cortices in the temporal lobes\n",
    "  - Stronger contralateral activation (left ear stimuli activate right hemisphere more, and vice versa)\n",
    "  - Peak responses typically occur around 100 ms (N100/M100) and 200 ms (P200/M200) post-stimulus\n",
    "\n",
    "### Visual Experiment\n",
    "The visual experiment involves presenting checkerboard patterns to the left and right visual fields separately:\n",
    "- **Stimulus type**: Black and white checkerboard pattern\n",
    "- **Presentation**: \n",
    "  - Left visual field (Event code: '3' or 'Visual/Left')\n",
    "  - Right visual field (Event code: '4' or 'Visual/Right')\n",
    "- **Duration**: 50 ms\n",
    "- **Visual angle**: Approximately 4 degrees, presented about 5 degrees to the left or right of fixation\n",
    "- **Contrast**: High contrast (black/white)\n",
    "- **Inter-stimulus interval**: Variable, around 1-1.5 seconds\n",
    "- **Neural response**: \n",
    "  - Left visual field stimuli primarily activate the right occipital cortex\n",
    "  - Right visual field stimuli primarily activate the left occipital cortex\n",
    "  - Characteristic components appear around 100 ms (P100/M100) and 170 ms (N170/M170) post-stimulus\n",
    "  - This contralateral activation pattern allows for clear demonstration of the retinotopic organization of the visual system\n",
    "\n",
    "## Research Applications:\n",
    "This dataset is ideal for demonstrating:\n",
    "- Basic preprocessing of MEG/EEG data\n",
    "- Evoked response analysis \n",
    "- Source localization techniques\n",
    "- Comparison between different sensor types\n",
    "- Time-frequency analysis\n",
    "- Contralateral organization of both auditory and visual systems\n",
    "- Differences in spatial and temporal patterns between auditory and visual processing\n",
    "- Hemispheric specialization and lateralization effects\n",
    "\n",
    "The data follows the standard organization used in MNE-Python, making it easy to access events, \n",
    "raw recordings, and metadata through the MNE API.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "\n",
    "import mne\n",
    "from mne.datasets import sample\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file /home/koutras/mne_data/MNE-sample-data/MEG/sample/sample_audvis_raw.fif...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Read a total of 3 projection items:\n",
      "        PCA-v1 (1 x 102)  idle\n",
      "        PCA-v2 (1 x 102)  idle\n",
      "        PCA-v3 (1 x 102)  idle\n",
      "    Range : 25800 ... 192599 =     42.956 ...   320.670 secs\n",
      "Ready.\n",
      "Reading 0 ... 166799  =      0.000 ...   277.714 secs...\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 1 - 30 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 1.00\n",
      "- Lower transition bandwidth: 1.00 Hz (-6 dB cutoff frequency: 0.50 Hz)\n",
      "- Upper passband edge: 30.00 Hz\n",
      "- Upper transition bandwidth: 7.50 Hz (-6 dB cutoff frequency: 33.75 Hz)\n",
      "- Filter length: 1983 samples (3.302 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.2s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<script type=\"text/javascript\">\n",
       "    // must be `var` (not `const`) because this can get embedded multiple times on a page\n",
       "var toggleVisibility = (className) => {\n",
       "\n",
       "    const elements = document.querySelectorAll(`.${className}`);\n",
       "\n",
       "    elements.forEach(element => {\n",
       "        if (element.classList.contains(\"mne-repr-section-header\")) {\n",
       "            return  // Don't collapse the section header row\n",
       "        }\n",
       "        element.classList.toggle(\"mne-repr-collapsed\");\n",
       "    });\n",
       "\n",
       "    // trigger caret to rotate\n",
       "    var sel = `.mne-repr-section-header.${className} > th.mne-repr-section-toggle > button`;\n",
       "    const button = document.querySelector(sel);\n",
       "    button.classList.toggle(\"collapsed\");\n",
       "\n",
       "    // adjust tooltip\n",
       "    sel = `tr.mne-repr-section-header.${className}`;\n",
       "    const secHeadRow = document.querySelector(sel);\n",
       "    secHeadRow.classList.toggle(\"collapsed\");\n",
       "    secHeadRow.title = secHeadRow.title === \"Hide section\" ? \"Show section\" : \"Hide section\";\n",
       "}\n",
       "</script>\n",
       "\n",
       "<style type=\"text/css\">\n",
       "    /*\n",
       "Styles in this section apply both to the sphinx-built website docs and to notebooks\n",
       "rendered in an IDE or in Jupyter. In our web docs, styles here are complemented by\n",
       "doc/_static/styles.css and other CSS files (e.g. from the sphinx theme, sphinx-gallery,\n",
       "or bootstrap). In IDEs/Jupyter, those style files are unavailable, so only the rules in\n",
       "this file apply (plus whatever default styling the IDE applies).\n",
       "*/\n",
       ".mne-repr-table {\n",
       "    display: inline;  /* prevent using full container width */\n",
       "}\n",
       ".mne-repr-table tr.mne-repr-section-header > th {\n",
       "    padding-top: 1rem;\n",
       "    text-align: left;\n",
       "    vertical-align: middle;\n",
       "}\n",
       ".mne-repr-section-toggle > button {\n",
       "    all: unset;\n",
       "    display: block;\n",
       "    height: 1rem;\n",
       "    width: 1rem;\n",
       "}\n",
       ".mne-repr-section-toggle > button > svg {\n",
       "    height: 60%;\n",
       "}\n",
       "\n",
       "/* transition (rotation) effects on the collapser button */\n",
       ".mne-repr-section-toggle > button.collapsed > svg {\n",
       "    transition: 0.1s ease-out;\n",
       "    transform: rotate(-90deg);\n",
       "}\n",
       ".mne-repr-section-toggle > button:not(.collapsed) > svg {\n",
       "    transition: 0.1s ease-out;\n",
       "    transform: rotate(0deg);\n",
       "}\n",
       "\n",
       "/* hide collapsed table rows */\n",
       ".mne-repr-collapsed {\n",
       "    display: none;\n",
       "}\n",
       "\n",
       "\n",
       "@layer {\n",
       "    /*\n",
       "    Selectors in a `@layer` will always be lower-precedence than selectors outside the\n",
       "    layer. So even though e.g. `div.output_html` is present in the sphinx-rendered\n",
       "    website docs, the styles here won't take effect there as long as some other rule\n",
       "    somewhere in the page's CSS targets the same element.\n",
       "\n",
       "    In IDEs or Jupyter notebooks, though, the CSS files from the sphinx theme,\n",
       "    sphinx-gallery, and bootstrap are unavailable, so these styles will apply.\n",
       "\n",
       "    Notes:\n",
       "\n",
       "    - the selector `.accordion-body` is for MNE Reports\n",
       "    - the selector `.output_html` is for VSCode's notebook interface\n",
       "    - the selector `.jp-RenderedHTML` is for Jupyter notebook\n",
       "    - variables starting with `--theme-` are VSCode-specific.\n",
       "    - variables starting with `--jp-` are Jupyter styles, *some of which* are also\n",
       "      available in VSCode. Here we try the `--theme-` variable first, then fall back to\n",
       "      the `--jp-` ones.\n",
       "    */\n",
       "    .mne-repr-table {\n",
       "        --mne-toggle-color: var(--theme-foreground, var(--jp-ui-font-color1));\n",
       "        --mne-button-bg-color: var(--theme-button-background, var(--jp-info-color0, var(--jp-content-link-color)));\n",
       "        --mne-button-fg-color: var(--theme-button-foreground, var(--jp-ui-inverse-font-color0, var(--jp-editor-background)));\n",
       "        --mne-button-hover-bg-color: var(--theme-button-hover-background, var(--jp-info-color1));\n",
       "        --mne-button-radius: var(--jp-border-radius, 0.25rem);\n",
       "    }\n",
       "    /* chevron position/alignment; in VSCode it looks ok without adjusting */\n",
       "    .accordion-body .mne-repr-section-toggle > button,\n",
       "    .jp-RenderedHTML .mne-repr-section-toggle > button {\n",
       "        padding: 0 0 45% 25% !important;\n",
       "    }\n",
       "    /* chevron color; MNE Report doesn't have light/dark mode */\n",
       "    div.output_html .mne-repr-section-toggle > button > svg > path,\n",
       "    .jp-RenderedHTML .mne-repr-section-toggle > button > svg > path {\n",
       "        fill: var(--mne-toggle-color);\n",
       "    }\n",
       "    .accordion-body .mne-ch-names-btn,\n",
       "    div.output_html .mne-ch-names-btn,\n",
       "    .jp-RenderedHTML .mne-ch-names-btn {\n",
       "        -webkit-border-radius: var(--mne-button-radius);\n",
       "        -moz-border-radius: var(--mne-button-radius);\n",
       "        border-radius: var(--mne-button-radius);\n",
       "        border: none;\n",
       "        background-image: none;\n",
       "        background-color: var(--mne-button-bg-color);\n",
       "        color: var(--mne-button-fg-color);\n",
       "        font-size: inherit;\n",
       "        min-width: 1.5rem;\n",
       "        padding: 0.25rem;\n",
       "        text-align: center;\n",
       "        text-decoration: none;\n",
       "    }\n",
       "    .accordion-body .mne-ch-names-btn:hover,\n",
       "    div.output_html .mne.ch-names-btn:hover,\n",
       "    .jp-RenderedHTML .mne-ch-names-btn:hover {\n",
       "        background-color: var(--mne-button-hover-bg-color);\n",
       "        text-decoration: underline;\n",
       "    }\n",
       "    .accordion-body .mne-ch-names-btn:focus-visible,\n",
       "    div.output_html .mne-ch-names-btn:focus-visible,\n",
       "    .jp-RenderedHTML .mne-ch-names-btn:focus-visible {\n",
       "        outline: 0.1875rem solid var(--mne-button-bg-color) !important;\n",
       "        outline-offset: 0.1875rem !important;\n",
       "    }\n",
       "}\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "<table class=\"table mne-repr-table\">\n",
       "    \n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "<tr class=\"mne-repr-section-header general-b5f8c676-7180-46e8-a550-f6ce025b6792\"\n",
       "     title=\"Hide section\" \n",
       "    onclick=\"toggleVisibility('general-b5f8c676-7180-46e8-a550-f6ce025b6792')\">\n",
       "    <th class=\"mne-repr-section-toggle\">\n",
       "        <button >\n",
       "            <svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 512 512\"><!--!Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free Copyright 2024 Fonticons, Inc.--><path d=\"M233.4 406.6c12.5 12.5 32.8 12.5 45.3 0l192-192c12.5-12.5 12.5-32.8 0-45.3s-32.8-12.5-45.3 0L256 338.7 86.6 169.4c-12.5-12.5-32.8-12.5-45.3 0s-12.5 32.8 0 45.3l192 192z\"/></svg>\n",
       "        </button>\n",
       "    </th>\n",
       "    <th colspan=\"2\">\n",
       "        <strong>General</strong>\n",
       "    </th>\n",
       "</tr>\n",
       "\n",
       "\n",
       "<tr class=\"repr-element general-b5f8c676-7180-46e8-a550-f6ce025b6792 \">\n",
       "    <td class=\"mne-repr-section-toggle\"></td>\n",
       "    <td>Filename(s)</td>\n",
       "    <td>\n",
       "        \n",
       "        sample_audvis_raw.fif\n",
       "        \n",
       "        \n",
       "    </td>\n",
       "</tr>\n",
       "\n",
       "<tr class=\"repr-element general-b5f8c676-7180-46e8-a550-f6ce025b6792 \">\n",
       "    <td class=\"mne-repr-section-toggle\"></td>\n",
       "    <td>MNE object type</td>\n",
       "    <td>Raw</td>\n",
       "</tr>\n",
       "<tr class=\"repr-element general-b5f8c676-7180-46e8-a550-f6ce025b6792 \">\n",
       "    <td class=\"mne-repr-section-toggle\"></td>\n",
       "    <td>Measurement date</td>\n",
       "    \n",
       "    <td>2002-12-03 at 19:01:10 UTC</td>\n",
       "    \n",
       "</tr>\n",
       "<tr class=\"repr-element general-b5f8c676-7180-46e8-a550-f6ce025b6792 \">\n",
       "    <td class=\"mne-repr-section-toggle\"></td>\n",
       "    <td>Participant</td>\n",
       "    \n",
       "    <td>Unknown</td>\n",
       "    \n",
       "</tr>\n",
       "<tr class=\"repr-element general-b5f8c676-7180-46e8-a550-f6ce025b6792 \">\n",
       "    <td class=\"mne-repr-section-toggle\"></td>\n",
       "    <td>Experimenter</td>\n",
       "    \n",
       "    <td>MEG</td>\n",
       "    \n",
       "</tr>\n",
       "    \n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "<tr class=\"mne-repr-section-header acquisition-69f4bcc7-1229-440b-882f-45cd13db3e46\"\n",
       "     title=\"Hide section\" \n",
       "    onclick=\"toggleVisibility('acquisition-69f4bcc7-1229-440b-882f-45cd13db3e46')\">\n",
       "    <th class=\"mne-repr-section-toggle\">\n",
       "        <button >\n",
       "            <svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 512 512\"><!--!Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free Copyright 2024 Fonticons, Inc.--><path d=\"M233.4 406.6c12.5 12.5 32.8 12.5 45.3 0l192-192c12.5-12.5 12.5-32.8 0-45.3s-32.8-12.5-45.3 0L256 338.7 86.6 169.4c-12.5-12.5-32.8-12.5-45.3 0s-12.5 32.8 0 45.3l192 192z\"/></svg>\n",
       "        </button>\n",
       "    </th>\n",
       "    <th colspan=\"2\">\n",
       "        <strong>Acquisition</strong>\n",
       "    </th>\n",
       "</tr>\n",
       "\n",
       "\n",
       "<tr class=\"repr-element acquisition-69f4bcc7-1229-440b-882f-45cd13db3e46 \">\n",
       "    <td class=\"mne-repr-section-toggle\"></td>\n",
       "    <td>Duration</td>\n",
       "    <td>00:04:38 (HH:MM:SS)</td>\n",
       "</tr>\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "<tr class=\"repr-element acquisition-69f4bcc7-1229-440b-882f-45cd13db3e46 \">\n",
       "    <td class=\"mne-repr-section-toggle\"></td>\n",
       "    <td>Sampling frequency</td>\n",
       "    <td>600.61 Hz</td>\n",
       "</tr>\n",
       "\n",
       "\n",
       "<tr class=\"repr-element acquisition-69f4bcc7-1229-440b-882f-45cd13db3e46 \">\n",
       "    <td class=\"mne-repr-section-toggle\"></td>\n",
       "    <td>Time points</td>\n",
       "    <td>166,800</td>\n",
       "</tr>\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "<tr class=\"mne-repr-section-header channels-a1771d80-8ca6-44a3-80f6-11742d27f0dd\"\n",
       "     title=\"Hide section\" \n",
       "    onclick=\"toggleVisibility('channels-a1771d80-8ca6-44a3-80f6-11742d27f0dd')\">\n",
       "    <th class=\"mne-repr-section-toggle\">\n",
       "        <button >\n",
       "            <svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 512 512\"><!--!Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free Copyright 2024 Fonticons, Inc.--><path d=\"M233.4 406.6c12.5 12.5 32.8 12.5 45.3 0l192-192c12.5-12.5 12.5-32.8 0-45.3s-32.8-12.5-45.3 0L256 338.7 86.6 169.4c-12.5-12.5-32.8-12.5-45.3 0s-12.5 32.8 0 45.3l192 192z\"/></svg>\n",
       "        </button>\n",
       "    </th>\n",
       "    <th colspan=\"2\">\n",
       "        <strong>Channels</strong>\n",
       "    </th>\n",
       "</tr>\n",
       "\n",
       "\n",
       "    \n",
       "<tr class=\"repr-element channels-a1771d80-8ca6-44a3-80f6-11742d27f0dd \">\n",
       "    <td class=\"mne-repr-section-toggle\"></td>\n",
       "    <td>EEG</td>\n",
       "    <td>\n",
       "        <button class=\"mne-ch-names-btn sd-sphinx-override sd-btn sd-btn-info sd-text-wrap sd-shadow-sm\" onclick=\"alert('Good EEG:\\n\\nEEG&nbsp;001, EEG&nbsp;002, EEG&nbsp;003, EEG&nbsp;004, EEG&nbsp;005, EEG&nbsp;006, EEG&nbsp;007, EEG&nbsp;008, EEG&nbsp;009, EEG&nbsp;010, EEG&nbsp;011, EEG&nbsp;012, EEG&nbsp;013, EEG&nbsp;014, EEG&nbsp;015, EEG&nbsp;016, EEG&nbsp;017, EEG&nbsp;018, EEG&nbsp;019, EEG&nbsp;020, EEG&nbsp;021, EEG&nbsp;022, EEG&nbsp;023, EEG&nbsp;024, EEG&nbsp;025, EEG&nbsp;026, EEG&nbsp;027, EEG&nbsp;028, EEG&nbsp;029, EEG&nbsp;030, EEG&nbsp;031, EEG&nbsp;032, EEG&nbsp;033, EEG&nbsp;034, EEG&nbsp;035, EEG&nbsp;036, EEG&nbsp;037, EEG&nbsp;038, EEG&nbsp;039, EEG&nbsp;040, EEG&nbsp;041, EEG&nbsp;042, EEG&nbsp;043, EEG&nbsp;044, EEG&nbsp;045, EEG&nbsp;046, EEG&nbsp;047, EEG&nbsp;048, EEG&nbsp;049, EEG&nbsp;050, EEG&nbsp;051, EEG&nbsp;052, EEG&nbsp;054, EEG&nbsp;055, EEG&nbsp;056, EEG&nbsp;057, EEG&nbsp;058, EEG&nbsp;059, EEG&nbsp;060')\" title=\"(Click to open in popup)&#13;&#13;EEG&nbsp;001, EEG&nbsp;002, EEG&nbsp;003, EEG&nbsp;004, EEG&nbsp;005, EEG&nbsp;006, EEG&nbsp;007, EEG&nbsp;008, EEG&nbsp;009, EEG&nbsp;010, EEG&nbsp;011, EEG&nbsp;012, EEG&nbsp;013, EEG&nbsp;014, EEG&nbsp;015, EEG&nbsp;016, EEG&nbsp;017, EEG&nbsp;018, EEG&nbsp;019, EEG&nbsp;020, EEG&nbsp;021, EEG&nbsp;022, EEG&nbsp;023, EEG&nbsp;024, EEG&nbsp;025, EEG&nbsp;026, EEG&nbsp;027, EEG&nbsp;028, EEG&nbsp;029, EEG&nbsp;030, EEG&nbsp;031, EEG&nbsp;032, EEG&nbsp;033, EEG&nbsp;034, EEG&nbsp;035, EEG&nbsp;036, EEG&nbsp;037, EEG&nbsp;038, EEG&nbsp;039, EEG&nbsp;040, EEG&nbsp;041, EEG&nbsp;042, EEG&nbsp;043, EEG&nbsp;044, EEG&nbsp;045, EEG&nbsp;046, EEG&nbsp;047, EEG&nbsp;048, EEG&nbsp;049, EEG&nbsp;050, EEG&nbsp;051, EEG&nbsp;052, EEG&nbsp;054, EEG&nbsp;055, EEG&nbsp;056, EEG&nbsp;057, EEG&nbsp;058, EEG&nbsp;059, EEG&nbsp;060\">\n",
       "            59\n",
       "        </button>\n",
       "\n",
       "        \n",
       "    </td>\n",
       "</tr>\n",
       "\n",
       "    \n",
       "<tr class=\"repr-element channels-a1771d80-8ca6-44a3-80f6-11742d27f0dd \">\n",
       "    <td class=\"mne-repr-section-toggle\"></td>\n",
       "    <td>Stimulus</td>\n",
       "    <td>\n",
       "        <button class=\"mne-ch-names-btn sd-sphinx-override sd-btn sd-btn-info sd-text-wrap sd-shadow-sm\" onclick=\"alert('Good Stimulus:\\n\\nSTI&nbsp;001, STI&nbsp;002, STI&nbsp;003, STI&nbsp;004, STI&nbsp;005, STI&nbsp;006, STI&nbsp;014, STI&nbsp;015, STI&nbsp;016')\" title=\"(Click to open in popup)&#13;&#13;STI&nbsp;001, STI&nbsp;002, STI&nbsp;003, STI&nbsp;004, STI&nbsp;005, STI&nbsp;006, STI&nbsp;014, STI&nbsp;015, STI&nbsp;016\">\n",
       "            9\n",
       "        </button>\n",
       "\n",
       "        \n",
       "    </td>\n",
       "</tr>\n",
       "\n",
       "\n",
       "<tr class=\"repr-element channels-a1771d80-8ca6-44a3-80f6-11742d27f0dd \">\n",
       "    <td class=\"mne-repr-section-toggle\"></td>\n",
       "    <td>Head & sensor digitization</td>\n",
       "    \n",
       "    <td>146 points</td>\n",
       "    \n",
       "</tr>\n",
       "    \n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "<tr class=\"mne-repr-section-header filters-0026343a-17f3-49ea-b17b-34c04b3eee49\"\n",
       "     title=\"Hide section\" \n",
       "    onclick=\"toggleVisibility('filters-0026343a-17f3-49ea-b17b-34c04b3eee49')\">\n",
       "    <th class=\"mne-repr-section-toggle\">\n",
       "        <button >\n",
       "            <svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 512 512\"><!--!Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free Copyright 2024 Fonticons, Inc.--><path d=\"M233.4 406.6c12.5 12.5 32.8 12.5 45.3 0l192-192c12.5-12.5 12.5-32.8 0-45.3s-32.8-12.5-45.3 0L256 338.7 86.6 169.4c-12.5-12.5-32.8-12.5-45.3 0s-12.5 32.8 0 45.3l192 192z\"/></svg>\n",
       "        </button>\n",
       "    </th>\n",
       "    <th colspan=\"2\">\n",
       "        <strong>Filters</strong>\n",
       "    </th>\n",
       "</tr>\n",
       "\n",
       "\n",
       "<tr class=\"repr-element filters-0026343a-17f3-49ea-b17b-34c04b3eee49 \">\n",
       "    <td class=\"mne-repr-section-toggle\"></td>\n",
       "    <td>Highpass</td>\n",
       "    <td>1.00 Hz</td>\n",
       "</tr>\n",
       "\n",
       "\n",
       "<tr class=\"repr-element filters-0026343a-17f3-49ea-b17b-34c04b3eee49 \">\n",
       "    <td class=\"mne-repr-section-toggle\"></td>\n",
       "    <td>Lowpass</td>\n",
       "    <td>30.00 Hz</td>\n",
       "</tr>\n",
       "\n",
       "\n",
       "</table>"
      ],
      "text/plain": [
       "<Raw | sample_audvis_raw.fif, 68 x 166800 (277.7 s), ~89.5 MiB, data loaded>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load MNE sample data\n",
    "data_path = sample.data_path()\n",
    "raw_fname = data_path / 'MEG' / 'sample' / 'sample_audvis_raw.fif'\n",
    "event_fname = data_path / 'MEG' / 'sample' / 'sample_audvis_raw-eve.fif'\n",
    "\n",
    "# Read raw EEG data\n",
    "raw = mne.io.read_raw_fif(raw_fname, preload=True)\n",
    "raw.pick_types(meg=False, eeg=True, stim=True)\n",
    "\n",
    "# Bandpass filter the raw data (1-30 Hz)\n",
    "raw.filter(1., 30., fir_design='firwin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make epochs from the data and plot them.\n",
    "First we define the different events. These are the Auditory/Left, Auditory/Right, Visual/Left, Visual/Right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "289 matching events found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting baseline interval to [-0.19979521315838786, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 289 events and 421 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "qt.core.qobject.connect: QObject::connect(QStyleHints, QStyleHints): unique connections require a pointer to member function of a QObject subclass\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<mne_qt_browser._pg_figure.MNEQtBrowser(0x58f6da6b0300) at 0x78946d5fcf80>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read events\n",
    "events = mne.read_events(event_fname)\n",
    "\n",
    "# Create epochs for auditory stimuli (event_id = 1)\n",
    "event_id = {'Auditory/Left': 1,\n",
    "            'Auditory/Right':2,\n",
    "            'Visual/Left':3,\n",
    "            'Visual/Right':4}\n",
    "            \n",
    "\n",
    "\n",
    "tmin, tmax = -0.2, 0.5  # define epoch interval\n",
    "epochs = mne.Epochs(raw, events, event_id, tmin, tmax, baseline=(None, 0), preload=True)\n",
    "\n",
    "# Plot epochs to visually inspect trials\n",
    "epochs.plot(n_epochs=10, title='Auditory Stimulus Epochs', scalings='auto')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make and plot the evoked response potentials. These are the mean values  of all epochs for the different channels.\n",
    "\n",
    "Looking at these ERP plots for left and right auditory stimulation, we can identify several important features:\n",
    "1. **Overall waveform morphology**:\n",
    "   - Both conditions show the classic auditory evoked potential components\n",
    "   - Clear negative peak around 100ms (N100)\n",
    "   - Prominent positive peak around 200ms (P200)\n",
    "   - Later components visible after 300ms\n",
    "\n",
    "2. **N100 component**:\n",
    "   - In both conditions, there's a pronounced negative deflection around 100-120ms\n",
    "   - The N100 appears to have slightly different amplitudes between conditions\n",
    "   - In the left auditory condition (top), the N100 peaks at approximately -10μV\n",
    "   - In the right auditory condition (bottom), similar amplitude but slight differences in the distribution across channels\n",
    "\n",
    "3. **P200 component**:\n",
    "   - Visible positive peak around 180-220ms in both conditions\n",
    "   - In the left auditory condition, P200 appears to have greater amplitude in some channels\n",
    "   - Channel variation suggests different spatial distributions of this component\n",
    "\n",
    "4. **Channel variation**:\n",
    "   - The colored lines represent different EEG channels\n",
    "   - The variation in amplitude across channels reflects the spatial distribution of activity\n",
    "   - Some channels show stronger responses than others, consistent with the topographic maps you showed previously\n",
    "\n",
    "5. **Hemispheric differences**:\n",
    "   - While it's difficult to identify specific channels from the plot, the variation in waveforms between conditions likely corresponds to the contralateral dominance pattern\n",
    "   - Channels over the right hemisphere would show stronger responses for left ear stimulation and vice versa\n",
    "\n",
    "6. **Post-stimulus variability**:\n",
    "   - After about 300ms, there's considerable variability between channels\n",
    "   - This reflects more individualized processing after the initial sensory components\n",
    "\n",
    "These ERP plots complement the topographic maps by showing the precise timing of the auditory responses, while also illustrating how the response varies across different scalp locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "evoked_all = epochs.average()\n",
    "# Plot ERP (Evoked response)\n",
    "evoked_left = epochs[\"Auditory/Left\"].average()\n",
    "evoked_left.plot()\n",
    "plt.title('Evoked Response - Left')\n",
    "evoked_right = epochs[\"Auditory/Right\"].average()\n",
    "evoked_right.plot()\n",
    "plt.title('Evoked Response - Right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next we plot the topographic plots for both cases at different time points after the stimuli.\n",
    "Note the topography in both cases in ~N100 and ~P200.\n",
    "\n",
    "### For the N100 component (around 94-117ms):\n",
    "\n",
    "#### Left auditory stimulation (top row):\n",
    "1. Strong negative (blue) activity predominantly in the **right** hemisphere.\n",
    "2. This negativity is centered in the **right fronto-central/temporal regions**\n",
    "3. **The contralateral nature (left ear → right hemisphere) is clearly visible**\n",
    "\n",
    "#### Right auditory stimulation (bottom row):\n",
    "1. Strong negative (blue) activity predominantly in the **left** hemisphere\n",
    "2. This negativity is centered in the **left fronto-central/temporal regions**\n",
    "3. **Again showing the expected contralateral activation pattern**\n",
    "\n",
    "### For the P200 component (around 183-228ms):\n",
    "\n",
    "#### Left auditory stimulation (top row):\n",
    "1. Strong positive (red) activity that appears most prominently in **central and right** hemisphere regions\n",
    "2. The positivity peaks around 206-228ms\n",
    "3. **Shows a broader, more diffuse distribution compared to the N100**\n",
    "\n",
    "#### Right auditory stimulation (bottom row):\n",
    "1. Strong positive (red) activity that is strongest in **central and left** hemisphere regions\n",
    "2. Similar timing to the left auditory P200\n",
    "3. **Again demonstrates the contralateral dominance pattern, though less pronounced than in the N100**\n",
    "\n",
    "### Key observations:\n",
    "\n",
    "1. The N100 shows stronger lateralization (more pronounced contralateral activation) than the P200\n",
    "2. The P200 has a more central and diffuse distribution, suggesting more bilateral processing at this later stage\n",
    "3. There's a clear polarity inversion from N100 (negative) to P200 (positive)\n",
    "4. The timing progression clearly shows the sequential processing stages of auditory information\n",
    "\n",
    "These topographic differences reflect the neurophysiological principle of contralateral dominance in auditory processing pathways, where stimuli presented to one ear produce stronger responses in the opposite hemisphere, particularly at earlier processing stages like the N100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = np.linspace(0.05, 0.25, 10)\n",
    "evoked_left.plot_topomap(times=times, colorbar=True)\n",
    "evoked_right.plot_topomap(times=times, colorbar=True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joint plots\n",
    "\n",
    "This combined visualization provides an excellent integration of the ERP waveforms with topographic maps at key time points. Looking at these joint plots, we can make several important observations:\n",
    "\n",
    "For Left Auditory Stimulation (top):\n",
    "1. **N100 component (0.095s)**:\n",
    "   - Strong negative (blue) activity predominantly in the right hemisphere\n",
    "   - The topographic map shows clear contralateral activation (left ear → right hemisphere)\n",
    "   - The ERP waveform shows this as a pronounced negative deflection across multiple channels\n",
    "\n",
    "2. **P200 component (0.205s)**:\n",
    "   - Clear positive (red) activity with a more central distribution\n",
    "   - The topography shows stronger activation in central and right regions\n",
    "   - The ERP shows this as a positive deflection following the N100\n",
    "\n",
    "3. **Late component (0.448s)**:\n",
    "   - Positive activity with a frontal and right hemisphere dominance\n",
    "   - Represents later cognitive processing of the auditory stimulus\n",
    "\n",
    "For Right Auditory Stimulation (bottom):\n",
    "1. **N100 component (0.088s)**:\n",
    "   - Strong negative (blue) activity predominantly in the left hemisphere\n",
    "   - Clear contralateral activation (right ear → left hemisphere)\n",
    "   - Similar latency to the left auditory N100, but with different spatial distribution\n",
    "\n",
    "2. **Intermediate component (0.163s)**:\n",
    "   - A transitional stage showing positive central activity with negative peripheral activity\n",
    "   - This time point differs from the top plot, highlighting potential differences in processing speed\n",
    "\n",
    "3. **P200 component (0.206s)**:\n",
    "   - Positive (red) activity with stronger representation in central and left regions\n",
    "   - Similar latency to the left auditory P200, but with different spatial distribution\n",
    "\n",
    "Key comparative observations:\n",
    "1. **Lateralization effects**:\n",
    "   - Both conditions clearly demonstrate the principle of contralateral dominance in auditory processing\n",
    "   - The N100 shows stronger lateralization than the P200 in both conditions\n",
    "\n",
    "2. **Temporal differences**:\n",
    "   - Slight timing differences in component peaks between conditions\n",
    "   - The right auditory condition shows an additional topography at 0.163s not highlighted in the left condition\n",
    "\n",
    "3. **Processing sequence**:\n",
    "   - Both conditions demonstrate the classic progression from early sensory processing (N100) to later perceptual/cognitive stages (P200 and beyond)\n",
    "   - The detailed evolution of the spatial distribution over time provides insight into how auditory information flows through brain networks\n",
    "\n",
    "These visualizations effectively illustrate the neurophysiological principles of auditory processing, showing both the temporal dynamics (from the ERP waveforms) and spatial distribution (from the topographic maps) of brain activity during lateralized auditory stimulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n"
     ]
    }
   ],
   "source": [
    "evoked_left.plot_joint()\n",
    "evoked_right.plot_joint()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image plots\n",
    "\n",
    "These images show EEG channel by time heatmaps for the left auditory (top) and right auditory (bottom) conditions. This visualization format is particularly useful for seeing patterns across all channels simultaneously.\n",
    "\n",
    "For the Left Auditory Stimulation (top):\n",
    "1. **N100 component** (~0.1s):\n",
    "   - Strong negative activity (dark blue) appears across multiple channels\n",
    "   - This negativity is more prominent in certain channel ranges (particularly channels 10-20), which likely correspond to right hemisphere electrodes\n",
    "   - The timing aligns with the N100 component we observed in previous visualizations\n",
    "\n",
    "2. **P200 component** (~0.2s):\n",
    "   - Clear positive activity (red) follows the N100\n",
    "   - This positive response appears distributed across channels\n",
    "   - Shows a distinct temporal pattern across different channel groupings\n",
    "\n",
    "3. **Channel distribution**:\n",
    "   - Different channels show varying response patterns\n",
    "   - Some channel clusters show stronger responses than others, reflecting the spatial organization of auditory processing\n",
    "\n",
    "For the Right Auditory Stimulation (bottom):\n",
    "1. **N100 component** (~0.1s):\n",
    "   - Strong negative activity (dark blue) but with a different distribution across channels\n",
    "   - The strongest negativity appears to be in different channel ranges compared to the left auditory condition, likely reflecting left hemisphere dominance\n",
    "\n",
    "2. **P200 component** (~0.2s):\n",
    "   - Positive activity (red/orange) following the N100\n",
    "   - The distribution across channels differs from the left auditory condition\n",
    "\n",
    "3. **Later components**:\n",
    "   - Both conditions show additional oscillatory patterns after 0.3s\n",
    "   - The patterns differ between conditions, suggesting different later processing\n",
    "\n",
    "Key comparative observations:\n",
    "1. **Channel differences**:\n",
    "   - The distribution of activity across channels differs between conditions\n",
    "   - This reflects the contralateral processing we saw in the topographic maps\n",
    "\n",
    "2. **Temporal sequence**:\n",
    "   - Both conditions show the classic N100-P200 sequence\n",
    "   - The timing of components is similar, but their distribution across channels differs\n",
    "\n",
    "3. **Channel clustering**:\n",
    "   - The activity appears to cluster in different channel groups between conditions\n",
    "   - This clustering likely corresponds to the lateralized activation patterns observed in the topographic maps\n",
    "\n",
    "These heatmaps provide an excellent overview of how the auditory responses vary across both time and space (channels), further supporting the lateralized processing patterns we've observed in the previous visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "evoked_left.plot_image()\n",
    "evoked_right.plot_image()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare Evoked\n",
    "\n",
    "These plots provide valuable comparative information between left and right auditory conditions:\n",
    "\n",
    "On the left plot (Mean evoked response):\n",
    "1. **N100 differences**:\n",
    "   - The blue line (auditory_left) shows a stronger negative peak around 0.1s compared to the orange line (auditory_right)\n",
    "   - The left auditory N100 appears to peak slightly earlier and with greater amplitude\n",
    "   - This indicates differences in early sensory processing depending on which ear was stimulated\n",
    "\n",
    "2. **P200 differences**:\n",
    "   - Left auditory (blue) shows a stronger positive deflection around 0.2s\n",
    "   - The morphology and timing of the P200 differs between conditions\n",
    "   - Left auditory P200 appears to have higher amplitude\n",
    "\n",
    "3. **Overall waveform differences**:\n",
    "   - The conditions show different oscillatory patterns throughout the time course\n",
    "   - Pre-stimulus activity also differs between conditions\n",
    "   - Later components (after 0.3s) show distinct patterns\n",
    "\n",
    "On the right plot (Global Field Power/GFP):\n",
    "1. **Overall signal strength**:\n",
    "   - GFP measures the spatial standard deviation across electrodes at each time point, representing the overall strength of the response regardless of topography\n",
    "   - Both conditions show a prominent peak around 0.1s, corresponding to the N100 timeframe\n",
    "   - The left auditory condition (blue) shows consistently higher GFP\n",
    "\n",
    "2. **Component strength**:\n",
    "   - The N100 component shows the highest GFP for both conditions, indicating this is when neural activity is most synchronized and strongest\n",
    "   - Left auditory stimulation produces greater overall field strength than right auditory\n",
    "   - This suggests potentially stronger or more synchronized neural responses for left ear stimulation\n",
    "\n",
    "3. **Temporal dynamics**:\n",
    "   - Both conditions show similar timing of major GFP peaks\n",
    "   - The relative difference in GFP magnitude remains fairly consistent throughout the epoch\n",
    "   - Secondary peaks after 0.2s show more variability between conditions\n",
    "\n",
    "These plots highlight important asymmetries in auditory processing:\n",
    "- The stronger response for left auditory stimulation (in both mean evoked and GFP) suggests potential right hemisphere dominance for auditory processing\n",
    "- The timing differences in components point to potentially different processing speeds for left versus right ear stimulation\n",
    "- The GFP differences indicate that not only does the spatial distribution of activity differ between conditions (as seen in the topographic maps), but also the overall strength of the neural response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combining channels using \"mean\"\n",
      "combining channels using \"mean\"\n",
      "combining channels using GFP (eeg channels)\n",
      "combining channels using GFP (eeg channels)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/biosignals/lib/python3.10/site-packages/mne_qt_browser/_pg_figure.py:3061: RuntimeWarning: Failed to disconnect (None) from signal \"triggered()\".\n",
      "  sig.disconnect()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 0 epochs: \n",
      "The following epochs were marked as bad and are dropped:\n",
      "[]\n",
      "Channels marked as bad:\n",
      "none\n"
     ]
    }
   ],
   "source": [
    "evokeds = dict(auditory_left=evoked_left, auditory_right=evoked_right)\n",
    "\n",
    "for combine in (\"mean\", \"gfp\"):\n",
    "    mne.viz.plot_compare_evokeds(evokeds,combine=combine)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next steps\n",
    "\n",
    "You can analyze the visual stimulation data from the MNE sample dataset, I'd recommend focusing on these key aspects:\n",
    "\n",
    "## Analysis Guidance for Visual Stimulation Data\n",
    "\n",
    "### Key Time Points to Examine:\n",
    "1. **P100 (around 80-120ms)**: The first major positive component, representing early visual processing\n",
    "2. **N170 (around 150-190ms)**: A prominent negative component associated with visual object processing\n",
    "3. **P300 (around 250-350ms)**: Later positive component reflecting higher-order cognitive processing\n",
    "\n",
    "### Topographical Areas to Focus On:\n",
    "1. **Occipital regions**: Primary visual areas (back of the head) for early visual responses\n",
    "2. **Lateralization patterns**: \n",
    "   - Left visual field stimuli → activity predominantly in right occipital areas\n",
    "   - Right visual field stimuli → activity predominantly in left occipital areas\n",
    "3. **Ventral visual stream**: Flow of activation from occipital to temporal regions\n",
    "\n",
    "### Specific Analyses to Assign:\n",
    "\n",
    "1. **Compare topographies between left and right visual field conditions**:\n",
    "   - Look for the contralateral organization (more pronounced than in auditory)\n",
    "   - Observe how the earliest component (P100) shows strongest contralateral activity\n",
    "   - Note how later components become more bilaterally distributed\n",
    "\n",
    "2. **Examine ERP waveforms from occipital electrodes**:\n",
    "   - Compare electrodes over left vs. right occipital regions\n",
    "   - Look for amplitude differences between contralateral and ipsilateral responses\n",
    "\n",
    "3. **Conduct PLV analysis**:\n",
    "   - Focus on connectivity between occipital regions and other areas\n",
    "   - Compare left vs. right visual field connectivity patterns\n",
    "   - Look for differences in the timing of increased connectivity\n",
    "\n",
    "4. **Create difference maps**:\n",
    "   - Generate left-right visual field contrast topographies\n",
    "   - Identify time points with maximum lateralization effects\n",
    "\n",
    "5. **Compare GFP between conditions**:\n",
    "   - Look for differences in overall response strength\n",
    "   - Identify peak timing differences between conditions\n",
    "\n",
    "The visual paradigm should show even clearer contralateral organization than the auditory data, making it an excellent demonstration of the retinotopic organization of the visual system. The occipital focus of activity (versus temporal for auditory) provides a good contrast for understanding sensory processing across different modalities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "biosignals",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
